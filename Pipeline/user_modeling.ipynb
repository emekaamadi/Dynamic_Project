{"cells":[{"cell_type":"markdown","metadata":{},"source":["This file is use to Analyze the modeling pipeline and modeling results."]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>time_stamp_x</th>\n","      <th>distance</th>\n","      <th>cab_type</th>\n","      <th>source</th>\n","      <th>destination</th>\n","      <th>name</th>\n","      <th>car_type</th>\n","      <th>weekday</th>\n","      <th>rush_hour</th>\n","      <th>temp</th>\n","      <th>clouds</th>\n","      <th>pressure</th>\n","      <th>rain</th>\n","      <th>humidity</th>\n","      <th>wind</th>\n","      <th>is_raining</th>\n","      <th>temp_groups</th>\n","      <th>surge_multiplier</th>\n","      <th>price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1543203646318</td>\n","      <td>3.03</td>\n","      <td>Lyft</td>\n","      <td>Boston University</td>\n","      <td>Theatre District</td>\n","      <td>Lux Black XL</td>\n","      <td>Luxury SUV</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>41.07</td>\n","      <td>0.86</td>\n","      <td>1014.39</td>\n","      <td>NaN</td>\n","      <td>0.92</td>\n","      <td>1.36</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>1.0</td>\n","      <td>34.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1543203646319</td>\n","      <td>1.30</td>\n","      <td>Uber</td>\n","      <td>South Station</td>\n","      <td>Theatre District</td>\n","      <td>Black</td>\n","      <td>Luxury</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>40.86</td>\n","      <td>0.87</td>\n","      <td>1014.39</td>\n","      <td>NaN</td>\n","      <td>0.93</td>\n","      <td>1.60</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>1.0</td>\n","      <td>18.5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1543203646320</td>\n","      <td>2.43</td>\n","      <td>Lyft</td>\n","      <td>Northeastern University</td>\n","      <td>Beacon Hill</td>\n","      <td>Lyft</td>\n","      <td>Base</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>40.81</td>\n","      <td>0.89</td>\n","      <td>1014.35</td>\n","      <td>NaN</td>\n","      <td>0.93</td>\n","      <td>1.36</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>1.0</td>\n","      <td>10.5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1543203646320</td>\n","      <td>2.71</td>\n","      <td>Uber</td>\n","      <td>Theatre District</td>\n","      <td>Fenway</td>\n","      <td>UberXL</td>\n","      <td>Base XL</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>40.80</td>\n","      <td>0.87</td>\n","      <td>1014.39</td>\n","      <td>NaN</td>\n","      <td>0.93</td>\n","      <td>1.55</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>1.0</td>\n","      <td>32.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1543203646320</td>\n","      <td>2.71</td>\n","      <td>Uber</td>\n","      <td>Theatre District</td>\n","      <td>Fenway</td>\n","      <td>UberX</td>\n","      <td>Base</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>40.80</td>\n","      <td>0.87</td>\n","      <td>1014.39</td>\n","      <td>NaN</td>\n","      <td>0.93</td>\n","      <td>1.55</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>1.0</td>\n","      <td>19.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    time_stamp_x  distance cab_type                   source   \n","0  1543203646318      3.03     Lyft        Boston University  \\\n","1  1543203646319      1.30     Uber            South Station   \n","2  1543203646320      2.43     Lyft  Northeastern University   \n","3  1543203646320      2.71     Uber         Theatre District   \n","4  1543203646320      2.71     Uber         Theatre District   \n","\n","        destination          name    car_type  weekday  rush_hour   temp   \n","0  Theatre District  Lux Black XL  Luxury SUV        1          0  41.07  \\\n","1  Theatre District         Black      Luxury        1          0  40.86   \n","2       Beacon Hill          Lyft        Base        1          0  40.81   \n","3            Fenway        UberXL     Base XL        1          0  40.80   \n","4            Fenway         UberX        Base        1          0  40.80   \n","\n","   clouds  pressure  rain  humidity  wind  is_raining  temp_groups   \n","0    0.86   1014.39   NaN      0.92  1.36           0           40  \\\n","1    0.87   1014.39   NaN      0.93  1.60           0           40   \n","2    0.89   1014.35   NaN      0.93  1.36           0           40   \n","3    0.87   1014.39   NaN      0.93  1.55           0           40   \n","4    0.87   1014.39   NaN      0.93  1.55           0           40   \n","\n","   surge_multiplier  price  \n","0               1.0   34.0  \n","1               1.0   18.5  \n","2               1.0   10.5  \n","3               1.0   32.0  \n","4               1.0   19.5  "]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.linear_model import LinearRegression, Ridge, Lasso, SGDRegressor\n","from sklearn.svm import SVR\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","from preprocess import *\n","\n","\n","# Load the data\n","data = pd.read_csv(\"../Cleaning_Engineering/base_cleaned.csv\")\n","data = data.drop(columns=['Unnamed: 0'])\n","\n","# Show the first few rows of the dataframe\n","data.head()\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["def data_transform(data):\n","\n","    # Separate the features (X) and the target variable (y)\n","    X = data.drop('price', axis=1)\n","    y = data['price']\n","\n","    # Preprocessing for numerical features\n","    numerical_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]\n","    numerical_transformer = StandardScaler()\n","\n","    # Preprocessing for categorical features\n","    categorical_cols = [cname for cname in X.columns if X[cname].dtype == 'object']\n","    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n","\n","    # Bundle preprocessing for numerical and categorical features\n","    preprocessor = ColumnTransformer(\n","        transformers=[\n","            ('num', numerical_transformer, numerical_cols),\n","            ('cat', categorical_transformer, categorical_cols)])\n","\n","    # Split the dataset into training (80%) and validation (20%) sets\n","    X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n","\n","    # Preprocessing of training data, fit_transform\n","    X_train_prepared = preprocessor.fit_transform(X_train)\n","    \n","    # Preprocessing of validation data, transform\n","    X_valid_prepared = preprocessor.transform(X_valid)\n","\n","    # Check the shape after preprocessing\n","    X_train_prepared.shape, X_valid_prepared.shape\n","\n","    final_columns = preprocessor.get_feature_names_out()\n","    return (X_train_prepared, y_train, X_valid_prepared, y_valid, final_columns)\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["def run_models(X_train_prepared, y_train, X_valid_prepared, y_valid):\n","    #Define a list of models\n","    models = [\n","        ('Linear Regression', LinearRegression()),\n","        ('Ridge Regression', Ridge(random_state=0)),\n","        ('Lasso Regression', Lasso(random_state=0)),\n","        ('Decision Tree Regression', DecisionTreeRegressor(random_state=0)),\n","        (\"SGD Regression\", SGDRegressor(random_state=0)),\n","        #('RandomForestRegressor', RandomForestRegressor(random_state=0)),\n","        ('GradienBoostingRegressor', GradientBoostingRegressor(random_state= 0)),\n","        #('SVR', SVR())\n","    ]\n","\n","    # List to store results\n","    results = []\n","    # Loop through the list of models\n","    for name, model in models:\n","        # Fit the model\n","        model.fit(X_train_prepared, y_train)\n","        \n","        # Predict on the validation set\n","        y_pred_valid = model.predict(X_valid_prepared)\n","        \n","        # Evaluate the model\n","        mse = mean_squared_error(y_valid, y_pred_valid)\n","        r2 = r2_score(y_valid, y_pred_valid)\n","        \n","        # Store the results\n","        results.append((name, mse, r2))\n","        \n","        # Print the results\n","\n","        print(f\"{name} - MSE: {mse:.2f}, R^2: {r2:.2f}\")\n","        if name == 'Decision Tree Regression':\n","            best_model = model\n","\n","    return (best_model,best_model.feature_importances_)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Linear Regression - MSE: 12.60, R^2: 0.84\n","Ridge Regression - MSE: 12.60, R^2: 0.84\n","Lasso Regression - MSE: 38.07, R^2: 0.52\n","Decision Tree Regression - MSE: 4.70, R^2: 0.94\n","SGD Regression - MSE: 12.61, R^2: 0.84\n","GradienBoostingRegressor - MSE: 7.31, R^2: 0.91\n"]}],"source":["# Model  the Base Data\n","X_train_prepared, y_train, X_valid_prepared, y_valid, final_columns = data_transform(get_base_data())\n","model, feature_importances = run_models(X_train_prepared, y_train, X_valid_prepared, y_valid)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MSE: 4.29, R^2: 0.95\n"]}],"source":["# Check for Overfitting By evaluating the Training Set\n","    \n","# Predict on the training set\n","y_pred_train = model.predict(X_train_prepared)\n","\n","# Evaluate the model\n","mse = mean_squared_error(y_train, y_pred_train)\n","r2 = r2_score(y_train, y_pred_train)\n","print(f\"MSE: {mse:.2f}, R^2: {r2:.2f}\")"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                                     feature  importance\n","33                  cat__car_type_Luxury SUV    0.560024\n","32                      cat__car_type_Luxury    0.204527\n","31                     cat__car_type_Base XL    0.067769\n","18                 cat__destination_Back Bay    0.019468\n","24                cat__destination_North End    0.018184\n","22       cat__destination_Financial District    0.017436\n","10            cat__source_Financial District    0.012848\n","6                       cat__source_Back Bay    0.012208\n","11              cat__source_Haymarket Square    0.009146\n","23         cat__destination_Haymarket Square    0.006860\n","34                      cat__car_type_Shared    0.006584\n","5                         cat__cab_type_Uber    0.006395\n","20        cat__destination_Boston University    0.006164\n","27            cat__destination_South Station    0.005410\n","8              cat__source_Boston University    0.005332\n","15                 cat__source_South Station    0.005124\n","12                     cat__source_North End    0.004931\n","26  cat__destination_Northeastern University    0.004844\n","21                   cat__destination_Fenway    0.004599\n","16              cat__source_Theatre District    0.002817\n","7                    cat__source_Beacon Hill    0.002492\n","9                         cat__source_Fenway    0.002379\n","19              cat__destination_Beacon Hill    0.002293\n","14       cat__source_Northeastern University    0.002062\n","25            cat__destination_North Station    0.001946\n","28         cat__destination_Theatre District    0.001835\n","4                         cat__cab_type_Lyft    0.001738\n","17                      cat__source_West End    0.001227\n","13                 cat__source_North Station    0.000915\n","29                 cat__destination_West End    0.000769\n","3                           num__temp_groups    0.000627\n","1                             num__rush_hour    0.000371\n","0                               num__weekday    0.000332\n","2                            num__is_raining    0.000302\n","35      cat__car_type_Wheel Chair Accessible    0.000022\n","30                        cat__car_type_Base    0.000020\n"]}],"source":["# Create a DataFrame to view the feature importances\n","features_df = pd.DataFrame({'feature': final_columns, \"importance\": feature_importances})\n","features_df = features_df.sort_values(by='importance', ascending=False)\n","\n","# Display the feature importances\n","print(features_df)\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Linear Regression - MSE: 17.15, R^2: 0.80\n","Ridge Regression - MSE: 17.15, R^2: 0.80\n","Lasso Regression - MSE: 43.21, R^2: 0.50\n","Decision Tree Regression - MSE: 8.50, R^2: 0.90\n","SGD Regression - MSE: 17.16, R^2: 0.80\n","GradienBoostingRegressor - MSE: 11.22, R^2: 0.87\n"]}],"source":["# Model  the Dynamic Data\n","X_train_prepared, y_train, X_valid_prepared, y_valid, final_columns = data_transform(get_dynamic_data())\n","model, feature_importances = run_models(X_train_prepared, y_train, X_valid_prepared, y_valid)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                                     feature  importance\n","33                  cat__car_type_Luxury SUV    0.549692\n","32                      cat__car_type_Luxury    0.208626\n","31                     cat__car_type_Base XL    0.067296\n","15                 cat__source_South Station    0.020181\n","24                cat__destination_North End    0.017617\n","18                 cat__destination_Back Bay    0.013322\n","22       cat__destination_Financial District    0.012656\n","10            cat__source_Financial District    0.012350\n","11              cat__source_Haymarket Square    0.010629\n","6                       cat__source_Back Bay    0.010284\n","23         cat__destination_Haymarket Square    0.006935\n","5                         cat__cab_type_Uber    0.006647\n","34                      cat__car_type_Shared    0.006620\n","20        cat__destination_Boston University    0.006223\n","27            cat__destination_South Station    0.005701\n","21                   cat__destination_Fenway    0.005663\n","26  cat__destination_Northeastern University    0.005544\n","12                     cat__source_North End    0.004808\n","16              cat__source_Theatre District    0.004110\n","25            cat__destination_North Station    0.003835\n","8              cat__source_Boston University    0.002950\n","4                         cat__cab_type_Lyft    0.002416\n","14       cat__source_Northeastern University    0.002387\n","9                         cat__source_Fenway    0.002310\n","19              cat__destination_Beacon Hill    0.002272\n","7                    cat__source_Beacon Hill    0.002090\n","28         cat__destination_Theatre District    0.001477\n","3                           num__temp_groups    0.001049\n","17                      cat__source_West End    0.000922\n","13                 cat__source_North Station    0.000876\n","29                 cat__destination_West End    0.000730\n","1                             num__rush_hour    0.000628\n","0                               num__weekday    0.000596\n","2                            num__is_raining    0.000519\n","30                        cat__car_type_Base    0.000020\n","35      cat__car_type_Wheel Chair Accessible    0.000019\n"]}],"source":["# Create a DataFrame to view the feature importances\n","features_df = pd.DataFrame({'feature': final_columns, \"importance\": feature_importances})\n","features_df = features_df.sort_values(by='importance', ascending=False)\n","\n","# Display the feature importances\n","print(features_df)\n"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Linear Regression - MSE: 86102.39, R^2: 0.38\n","Ridge Regression - MSE: 71454.32, R^2: 0.49\n","Lasso Regression - MSE: 58939.17, R^2: 0.58\n","Decision Tree Regression - MSE: 0.00, R^2: 1.00\n","SGD Regression - MSE: 58925.90, R^2: 0.58\n","GradienBoostingRegressor - MSE: 19666.77, R^2: 0.86\n"]}],"source":["# Model  the Demand Data\n","X_train_prepared, y_train, X_valid_prepared, y_valid, final_columns = data_transform(get_demand_data())\n","model, feature_importances = run_models(X_train_prepared, y_train, X_valid_prepared, y_valid)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["# These functions are specfically for testing how the models perform specifically on the surge data\n","def data_transform_surge(data):\n","    # Separate the features (X) and the target variable (y)\n","    X = data.drop('price', axis=1)\n","    y = data['price']\n","\n","    # Preprocessing for numerical features\n","    numerical_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]\n","    numerical_transformer = StandardScaler()\n","\n","    # Preprocessing for categorical features\n","    categorical_cols = [cname for cname in X.columns if X[cname].dtype == 'object']\n","    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n","\n","    # Bundle preprocessing for numerical and categorical features\n","    preprocessor = ColumnTransformer(\n","        transformers=[\n","            ('num', numerical_transformer, numerical_cols),\n","            ('cat', categorical_transformer, categorical_cols)])\n","    \n","    # Split the dataset into training (80%) and validation (20%) sets\n","    X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n","\n","    # Save the indices of the validation set\n","    valid_indices = X_valid.index\n","\n","    # Preprocessing of training data, fit_transform\n","    X_train_prepared = preprocessor.fit_transform(X_train)\n","    \n","    # Preprocessing of validation data, transform\n","    X_valid_prepared = preprocessor.transform(X_valid)\n","\n","    # Check the shape after preprocessing\n","    X_train_prepared.shape, X_valid_prepared.shape\n","\n","    final_columns = preprocessor.get_feature_names_out()\n","    return (X_train_prepared, y_train, X_valid_prepared, y_valid, final_columns, valid_indices)\n","\n","\n","def run_models_surge(X_train_prepared, y_train, X_valid_prepared, y_valid, valid_indices):\n","    models = [\n","        ('Linear Regression', LinearRegression()),\n","        ('Ridge Regression', Ridge(random_state=0)),\n","        ('Lasso Regression', Lasso(random_state=0)),\n","        ('Decision Tree Regression', DecisionTreeRegressor(random_state=0)),\n","        (\"SGD Regression\", SGDRegressor(random_state=0)),\n","        #('RandomForestRegressor', RandomForestRegressor(random_state=0)),\n","        ('GradienBoostingRegressor', GradientBoostingRegressor(random_state= 0)),\n","        #('SVR', SVR())\n","    ]\n","    results = []\n","    for name, model in models:\n","        # ... [existing code] ...\n","        model.fit(X_train_prepared, y_train)\n","        # Filter X_valid and y_valid for surge_multiplier > 1\n","        surge_indices = data.loc[valid_indices, 'surge_multiplier'] > 1\n","        X_valid_surge = X_valid_prepared[surge_indices]\n","        y_valid_surge = y_valid[surge_indices]\n","\n","        # Predict and evaluate on surge data\n","        y_pred_surge = model.predict(X_valid_surge)\n","        mse_surge = mean_squared_error(y_valid_surge, y_pred_surge)\n","        r2_surge = r2_score(y_valid_surge, y_pred_surge)\n","        results.append((name, mse_surge, r2_surge))\n","        print(f\"{name} (Surge Data) - MSE: {mse_surge:.2f}, R^2: {r2_surge:.2f}\")\n","\n","    \n","\n"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Linear Regression (Surge Data) - MSE: 151.09, R^2: 0.24\n","Ridge Regression (Surge Data) - MSE: 151.09, R^2: 0.24\n","Lasso Regression (Surge Data) - MSE: 246.61, R^2: -0.24\n","Decision Tree Regression (Surge Data) - MSE: 112.26, R^2: 0.44\n","SGD Regression (Surge Data) - MSE: 151.62, R^2: 0.24\n","GradienBoostingRegressor (Surge Data) - MSE: 133.32, R^2: 0.33\n"]}],"source":["# test the Dynamic Model on Surge > 1 Data Only \n","X_train_prepared, y_train, X_valid_prepared, y_valid, final_columns,valid_indices = data_transform_surge(get_dynamic_data())\n","run_models_surge(X_train_prepared, y_train, X_valid_prepared, y_valid, valid_indices)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Best model - MSE: 4.70, R^2: 0.94\n"]}],"source":["# Gris Search for Hyper Parameter Tuning\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import GridSearchCV\n","\n","data = get_base_data()\n","# Separate the features (X) and the target variable (y)\n","X = data.drop('price', axis=1)\n","y = data['price']\n","\n","\n","# Preprocessing for numerical features\n","numerical_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]\n","numerical_transformer = StandardScaler()\n","\n","# Preprocessing for categorical features\n","categorical_cols = [cname for cname in X.columns if X[cname].dtype == 'object']\n","categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n","\n","# Bundle preprocessing for numerical and categorical features\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numerical_transformer, numerical_cols),\n","        ('cat', categorical_transformer, categorical_cols)])\n","# Define the pipeline\n","pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n","                           ('regressor', DecisionTreeRegressor(random_state=0))])\n","\n","# Define the parameter grid to search\n","param_grid = {\n","    'regressor__max_depth': [3, 5, 10, 20, 30],\n","    'regressor__min_samples_split': [2, 4, 6]\n","}\n","\n","# Set up the grid search with cross-validation\n","grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n","\n","X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n","# Fit the grid search to the data\n","grid_search.fit(X_train, y_train)\n","\n","# Get the best estimator\n","best_model = grid_search.best_estimator_\n","\n","# Predict and evaluate\n","y_pred_valid = best_model.predict(X_valid)\n","mse = mean_squared_error(y_valid, y_pred_valid)\n","r2 = r2_score(y_valid, y_pred_valid)\n","\n","print(f\"Best model - MSE: {mse:.2f}, R^2: {r2:.2f}\")\n"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/plain":["{'regressor__max_depth': 30, 'regressor__min_samples_split': 6}"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["grid_search.best_params_"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"c12a693207de4a0d92eabf24fb01f952","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}
