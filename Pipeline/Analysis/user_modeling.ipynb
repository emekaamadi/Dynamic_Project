{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"cell_id":"2e70a67c377f4c499498183a37f69e36","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":914,"execution_start":1699487122609,"source_hash":null},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>time_stamp_x</th>\n","      <th>distance</th>\n","      <th>cab_type</th>\n","      <th>source</th>\n","      <th>destination</th>\n","      <th>name</th>\n","      <th>car_type</th>\n","      <th>weekday</th>\n","      <th>rush_hour</th>\n","      <th>temp</th>\n","      <th>clouds</th>\n","      <th>pressure</th>\n","      <th>rain</th>\n","      <th>humidity</th>\n","      <th>wind</th>\n","      <th>is_raining</th>\n","      <th>temp_groups</th>\n","      <th>surge_multiplier</th>\n","      <th>price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1543203646318</td>\n","      <td>3.03</td>\n","      <td>Lyft</td>\n","      <td>Boston University</td>\n","      <td>Theatre District</td>\n","      <td>Lux Black XL</td>\n","      <td>Luxury SUV</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>41.07</td>\n","      <td>0.86</td>\n","      <td>1014.39</td>\n","      <td>NaN</td>\n","      <td>0.92</td>\n","      <td>1.36</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>1.0</td>\n","      <td>34.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1543203646319</td>\n","      <td>1.30</td>\n","      <td>Uber</td>\n","      <td>South Station</td>\n","      <td>Theatre District</td>\n","      <td>Black</td>\n","      <td>Luxury</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>40.86</td>\n","      <td>0.87</td>\n","      <td>1014.39</td>\n","      <td>NaN</td>\n","      <td>0.93</td>\n","      <td>1.60</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>1.0</td>\n","      <td>18.5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1543203646320</td>\n","      <td>2.43</td>\n","      <td>Lyft</td>\n","      <td>Northeastern University</td>\n","      <td>Beacon Hill</td>\n","      <td>Lyft</td>\n","      <td>Base</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>40.81</td>\n","      <td>0.89</td>\n","      <td>1014.35</td>\n","      <td>NaN</td>\n","      <td>0.93</td>\n","      <td>1.36</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>1.0</td>\n","      <td>10.5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>1543203646320</td>\n","      <td>2.71</td>\n","      <td>Uber</td>\n","      <td>Theatre District</td>\n","      <td>Fenway</td>\n","      <td>UberXL</td>\n","      <td>Base XL</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>40.80</td>\n","      <td>0.87</td>\n","      <td>1014.39</td>\n","      <td>NaN</td>\n","      <td>0.93</td>\n","      <td>1.55</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>1.0</td>\n","      <td>32.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>1543203646320</td>\n","      <td>2.71</td>\n","      <td>Uber</td>\n","      <td>Theatre District</td>\n","      <td>Fenway</td>\n","      <td>UberX</td>\n","      <td>Base</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>40.80</td>\n","      <td>0.87</td>\n","      <td>1014.39</td>\n","      <td>NaN</td>\n","      <td>0.93</td>\n","      <td>1.55</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>1.0</td>\n","      <td>19.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0   time_stamp_x  distance cab_type                   source   \n","0           0  1543203646318      3.03     Lyft        Boston University  \\\n","1           1  1543203646319      1.30     Uber            South Station   \n","2           2  1543203646320      2.43     Lyft  Northeastern University   \n","3           3  1543203646320      2.71     Uber         Theatre District   \n","4           4  1543203646320      2.71     Uber         Theatre District   \n","\n","        destination          name    car_type  weekday  rush_hour   temp   \n","0  Theatre District  Lux Black XL  Luxury SUV        1          0  41.07  \\\n","1  Theatre District         Black      Luxury        1          0  40.86   \n","2       Beacon Hill          Lyft        Base        1          0  40.81   \n","3            Fenway        UberXL     Base XL        1          0  40.80   \n","4            Fenway         UberX        Base        1          0  40.80   \n","\n","   clouds  pressure  rain  humidity  wind  is_raining  temp_groups   \n","0    0.86   1014.39   NaN      0.92  1.36           0           40  \\\n","1    0.87   1014.39   NaN      0.93  1.60           0           40   \n","2    0.89   1014.35   NaN      0.93  1.36           0           40   \n","3    0.87   1014.39   NaN      0.93  1.55           0           40   \n","4    0.87   1014.39   NaN      0.93  1.55           0           40   \n","\n","   surge_multiplier  price  \n","0               1.0   34.0  \n","1               1.0   18.5  \n","2               1.0   10.5  \n","3               1.0   32.0  \n","4               1.0   19.5  "]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.linear_model import LinearRegression, Ridge, Lasso, SGDRegressor\n","from sklearn.svm import SVR\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","\n","\n","# Load the data\n","data = pd.read_csv(\"../Cleaning_Engineering/base_cleaned.csv\")\n","\n","# Show the first few rows of the dataframe\n","data.head()\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["from preprocess import *"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def data_transform(data):\n","\n","    # Separate the features (X) and the target variable (y)\n","    X = data.drop('price', axis=1)\n","    y = data['price']\n","\n","    # Preprocessing for numerical features\n","    numerical_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]\n","    numerical_transformer = StandardScaler()\n","\n","    # Preprocessing for categorical features\n","    categorical_cols = [cname for cname in X.columns if X[cname].dtype == 'object']\n","    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n","\n","    # Bundle preprocessing for numerical and categorical features\n","    preprocessor = ColumnTransformer(\n","        transformers=[\n","            ('num', numerical_transformer, numerical_cols),\n","            ('cat', categorical_transformer, categorical_cols)])\n","\n","    # Split the dataset into training (80%) and validation (20%) sets\n","    X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n","\n","    # Preprocessing of training data, fit_transform\n","    X_train_prepared = preprocessor.fit_transform(X_train)\n","    \n","    # Preprocessing of validation data, transform\n","    X_valid_prepared = preprocessor.transform(X_valid)\n","\n","    # Check the shape after preprocessing\n","    X_train_prepared.shape, X_valid_prepared.shape\n","\n","    final_columns = preprocessor.get_feature_names_out()\n","    return (X_train_prepared, y_train, X_valid_prepared, y_valid, final_columns)\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def run_models(X_train_prepared, y_train, X_valid_prepared, y_valid):\n","    #Define a list of models\n","    models = [\n","        ('Linear Regression', LinearRegression()),\n","        ('Ridge Regression', Ridge(random_state=0)),\n","        ('Lasso Regression', Lasso(random_state=0)),\n","        ('Decision Tree Regression', DecisionTreeRegressor(random_state=0)),\n","        (\"SGD Regression\", SGDRegressor(random_state=0)),\n","        #('RandomForestRegressor', RandomForestRegressor(random_state=0)),\n","        ('GradienBoostingRegressor', GradientBoostingRegressor(random_state= 0)),\n","        #('SVR', SVR())\n","    ]\n","\n","    # List to store results\n","    results = []\n","    # Loop through the list of models\n","    for name, model in models:\n","        # Fit the model\n","        model.fit(X_train_prepared, y_train)\n","        \n","        # Predict on the validation set\n","        y_pred_valid = model.predict(X_valid_prepared)\n","        \n","        # Evaluate the model\n","        mse = mean_squared_error(y_valid, y_pred_valid)\n","        r2 = r2_score(y_valid, y_pred_valid)\n","        \n","        # Store the results\n","        results.append((name, mse, r2))\n","        \n","        # Print the results\n","\n","        print(f\"{name} - MSE: {mse:.2f}, R^2: {r2:.2f}\")\n","        if name == 'Decision Tree Regression':\n","            best_model = model\n","\n","    return (best_model,best_model.feature_importances_)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["data = data.drop(columns=['Unnamed: 0'])\n","#data[\"rain\"].fillna(0.0, inplace=True)\n","#test_data = data.iloc[int(data.shape[0]*.9):]\n","#data = data.iloc[:int(data.shape[0]*.9)]\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["user_data = data[[\"cab_type\", \"source\", \"destination\", \"car_type\", \"weekday\", \"rush_hour\", \"is_raining\", \"temp_groups\", \"surge_multiplier\", \"price\"]]"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["user_data_no_surge = user_data[user_data[\"surge_multiplier\"] == 1.0]\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Linear Regression - MSE: 12.60, R^2: 0.84\n","Ridge Regression - MSE: 12.60, R^2: 0.84\n","Lasso Regression - MSE: 38.07, R^2: 0.52\n","Decision Tree Regression - MSE: 4.70, R^2: 0.94\n","SGD Regression - MSE: 12.61, R^2: 0.84\n","GradienBoostingRegressor - MSE: 7.31, R^2: 0.91\n"]}],"source":["X_train_prepared, y_train, X_valid_prepared, y_valid, final_columns = data_transform(user_data_no_surge)\n","model, feature_importances = run_models(X_train_prepared, y_train, X_valid_prepared, y_valid)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Linear Regression - MSE: 12.60, R^2: 0.84\n","Ridge Regression - MSE: 12.60, R^2: 0.84\n","Lasso Regression - MSE: 38.07, R^2: 0.52\n","Decision Tree Regression - MSE: 4.70, R^2: 0.94\n","SGD Regression - MSE: 12.61, R^2: 0.84\n","GradienBoostingRegressor - MSE: 7.31, R^2: 0.91\n"]}],"source":["X_train_prepared, y_train, X_valid_prepared, y_valid, final_columns = data_transform(get_base_data())\n","model, feature_importances = run_models(X_train_prepared, y_train, X_valid_prepared, y_valid)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Linear Regression - MSE: 17.15, R^2: 0.80\n","Ridge Regression - MSE: 17.15, R^2: 0.80\n","Lasso Regression - MSE: 43.21, R^2: 0.50\n","Decision Tree Regression - MSE: 8.50, R^2: 0.90\n","SGD Regression - MSE: 17.16, R^2: 0.80\n","GradienBoostingRegressor - MSE: 11.22, R^2: 0.87\n"]}],"source":["X_train_prepared, y_train, X_valid_prepared, y_valid, final_columns = data_transform(get_dynamic_data())\n","model, feature_importances = run_models(X_train_prepared, y_train, X_valid_prepared, y_valid)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# These functions are specfically for testing how the models perform specifically on the surge data\n","\n","\n","def data_transform_surge(data):\n","    # Separate the features (X) and the target variable (y)\n","    X = data.drop('price', axis=1)\n","    y = data['price']\n","\n","    # Preprocessing for numerical features\n","    numerical_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]\n","    numerical_transformer = StandardScaler()\n","\n","    # Preprocessing for categorical features\n","    categorical_cols = [cname for cname in X.columns if X[cname].dtype == 'object']\n","    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n","\n","    # Bundle preprocessing for numerical and categorical features\n","    preprocessor = ColumnTransformer(\n","        transformers=[\n","            ('num', numerical_transformer, numerical_cols),\n","            ('cat', categorical_transformer, categorical_cols)])\n","    \n","    # Split the dataset into training (80%) and validation (20%) sets\n","    X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n","\n","    # Save the indices of the validation set\n","    valid_indices = X_valid.index\n","\n","    # Preprocessing of training data, fit_transform\n","    X_train_prepared = preprocessor.fit_transform(X_train)\n","    \n","    # Preprocessing of validation data, transform\n","    X_valid_prepared = preprocessor.transform(X_valid)\n","\n","    # Check the shape after preprocessing\n","    X_train_prepared.shape, X_valid_prepared.shape\n","\n","    final_columns = preprocessor.get_feature_names_out()\n","    return (X_train_prepared, y_train, X_valid_prepared, y_valid, final_columns, valid_indices)\n","\n","\n","def run_models_surge(X_train_prepared, y_train, X_valid_prepared, y_valid, valid_indices):\n","    models = [\n","        ('Linear Regression', LinearRegression()),\n","        ('Ridge Regression', Ridge(random_state=0)),\n","        ('Lasso Regression', Lasso(random_state=0)),\n","        ('Decision Tree Regression', DecisionTreeRegressor(random_state=0)),\n","        (\"SGD Regression\", SGDRegressor(random_state=0)),\n","        #('RandomForestRegressor', RandomForestRegressor(random_state=0)),\n","        ('GradienBoostingRegressor', GradientBoostingRegressor(random_state= 0)),\n","        #('SVR', SVR())\n","    ]\n","    results = []\n","    for name, model in models:\n","        # ... [existing code] ...\n","        model.fit(X_train_prepared, y_train)\n","        # Filter X_valid and y_valid for surge_multiplier > 1\n","        surge_indices = data.loc[valid_indices, 'surge_multiplier'] > 1\n","        X_valid_surge = X_valid_prepared[surge_indices]\n","        y_valid_surge = y_valid[surge_indices]\n","\n","        # Predict and evaluate on surge data\n","        y_pred_surge = model.predict(X_valid_surge)\n","        mse_surge = mean_squared_error(y_valid_surge, y_pred_surge)\n","        r2_surge = r2_score(y_valid_surge, y_pred_surge)\n","        results.append((name, mse_surge, r2_surge))\n","        print(f\"{name} (Surge Data) - MSE: {mse_surge:.2f}, R^2: {r2_surge:.2f}\")\n","\n","    \n","\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(4151,) (127596,)\n","Linear Regression (Surge Data) - MSE: 60.98, R^2: 0.69\n","(4151,) (127596,)\n","Ridge Regression (Surge Data) - MSE: 60.98, R^2: 0.69\n","(4151,) (127596,)\n","Lasso Regression (Surge Data) - MSE: 142.10, R^2: 0.29\n","(4151,) (127596,)\n","Decision Tree Regression (Surge Data) - MSE: 19.28, R^2: 0.90\n","(4151,) (127596,)\n","SGD Regression (Surge Data) - MSE: 62.45, R^2: 0.69\n","(4151,) (127596,)\n","GradienBoostingRegressor (Surge Data) - MSE: 29.87, R^2: 0.85\n"]}],"source":["X_train_prepared, y_train, X_valid_prepared, y_valid, final_columns,valid_indices = data_transform_surge(user_data)\n","run_models_surge(X_train_prepared, y_train, X_valid_prepared, y_valid, valid_indices)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                                     feature  importance\n","34                  cat__car_type_Luxury SUV    0.560326\n","33                      cat__car_type_Luxury    0.204222\n","32                     cat__car_type_Base XL    0.067297\n","19                 cat__destination_Back Bay    0.018861\n","25                cat__destination_North End    0.016605\n","23       cat__destination_Financial District    0.014897\n","7                       cat__source_Back Bay    0.012584\n","11            cat__source_Financial District    0.012466\n","16                 cat__source_South Station    0.009621\n","12              cat__source_Haymarket Square    0.009144\n","28            cat__destination_South Station    0.007074\n","24         cat__destination_Haymarket Square    0.007062\n","35                      cat__car_type_Shared    0.006627\n","21        cat__destination_Boston University    0.006105\n","5                         cat__cab_type_Lyft    0.006102\n","13                     cat__source_North End    0.005195\n","27  cat__destination_Northeastern University    0.004986\n","9              cat__source_Boston University    0.004661\n","22                   cat__destination_Fenway    0.004549\n","17              cat__source_Theatre District    0.002902\n","20              cat__destination_Beacon Hill    0.002572\n","8                    cat__source_Beacon Hill    0.002498\n","6                         cat__cab_type_Uber    0.002058\n","29         cat__destination_Theatre District    0.001987\n","10                        cat__source_Fenway    0.001775\n","26            cat__destination_North Station    0.001726\n","15       cat__source_Northeastern University    0.001625\n","18                      cat__source_West End    0.001087\n","14                 cat__source_North Station    0.000930\n","3                           num__temp_groups    0.000697\n","30                 cat__destination_West End    0.000644\n","1                             num__rush_hour    0.000392\n","0                               num__weekday    0.000366\n","2                            num__is_raining    0.000319\n","31                        cat__car_type_Base    0.000023\n","36      cat__car_type_Wheel Chair Accessible    0.000016\n","4                      num__surge_multiplier    0.000000\n"]}],"source":["# Create a DataFrame to view the feature importances\n","features_df = pd.DataFrame({'feature': final_columns, \"importance\": feature_importances})\n","features_df = features_df.sort_values(by='importance', ascending=False)\n","\n","# Display the feature importances\n","print(features_df)\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Linear Regression - MSE: 14.02, R^2: 0.84\n","Ridge Regression - MSE: 14.02, R^2: 0.84\n","Lasso Regression - MSE: 40.33, R^2: 0.54\n","Decision Tree Regression - MSE: 5.10, R^2: 0.94\n","SGD Regression - MSE: 14.07, R^2: 0.84\n","GradienBoostingRegressor - MSE: 8.27, R^2: 0.90\n"]}],"source":["user_data_surge = user_data\n","X_train_prepared, y_train, X_valid_prepared, y_valid, final_columns = data_transform(user_data_surge)\n","model, feature_importances = run_models(X_train_prepared, y_train, X_valid_prepared, y_valid)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                                     feature  importance\n","33                  cat__car_type_Luxury SUV    0.433046\n","4                      num__surge_multiplier    0.165543\n","32                      cat__car_type_Luxury    0.143077\n","30                        cat__car_type_Base    0.038293\n","22       cat__destination_Financial District    0.028351\n","15                 cat__source_South Station    0.025064\n","24                cat__destination_North End    0.019416\n","6                       cat__source_Back Bay    0.012812\n","10            cat__source_Financial District    0.012327\n","27            cat__destination_South Station    0.010119\n","20        cat__destination_Boston University    0.009949\n","25            cat__destination_North Station    0.009560\n","18                 cat__destination_Back Bay    0.009421\n","23         cat__destination_Haymarket Square    0.009057\n","12                     cat__source_North End    0.008862\n","16              cat__source_Theatre District    0.007723\n","3                           num__temp_groups    0.007167\n","11              cat__source_Haymarket Square    0.007078\n","21                   cat__destination_Fenway    0.005468\n","26  cat__destination_Northeastern University    0.005207\n","0                               num__weekday    0.004066\n","1                             num__rush_hour    0.003880\n","7                    cat__source_Beacon Hill    0.003625\n","8              cat__source_Boston University    0.003301\n","29                 cat__destination_West End    0.003100\n","2                            num__is_raining    0.002867\n","28         cat__destination_Theatre District    0.002825\n","19              cat__destination_Beacon Hill    0.002389\n","14       cat__source_Northeastern University    0.002348\n","13                 cat__source_North Station    0.001552\n","9                         cat__source_Fenway    0.001416\n","17                      cat__source_West End    0.001090\n","5                         cat__cab_type_Lyft    0.000000\n","31                     cat__car_type_Base XL    0.000000\n"]}],"source":["# Create a DataFrame to view the feature importances\n","features_df = pd.DataFrame({'feature': final_columns, \"importance\": feature_importances})\n","features_df = features_df.sort_values(by='importance', ascending=False)\n","\n","# Display the feature importances\n","print(features_df)\n"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/plain":["32"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["model.get_depth()"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MSE: 7.52, R^2: 0.96\n"]}],"source":["# Check for Overfitting By evaluating the Training Set\n","    \n","# Predict on the validation set\n","y_pred_train = model.predict(X_train_prepared)\n","\n","# Evaluate the model\n","mse = mean_squared_error(y_train, y_pred_train)\n","r2 = r2_score(y_train, y_pred_train)\n","print(f\"MSE: {mse:.2f}, R^2: {r2:.2f}\")"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Best model - MSE: 4.70, R^2: 0.94\n"]}],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import GridSearchCV\n","\n","data = get_base_data()\n","# Separate the features (X) and the target variable (y)\n","X = data.drop('price', axis=1)\n","y = data['price']\n","\n","\n","# Preprocessing for numerical features\n","numerical_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]\n","numerical_transformer = StandardScaler()\n","\n","# Preprocessing for categorical features\n","categorical_cols = [cname for cname in X.columns if X[cname].dtype == 'object']\n","categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n","\n","# Bundle preprocessing for numerical and categorical features\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numerical_transformer, numerical_cols),\n","        ('cat', categorical_transformer, categorical_cols)])\n","# Define the pipeline\n","pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n","                           ('regressor', DecisionTreeRegressor(random_state=0))])\n","\n","# Define the parameter grid to search\n","param_grid = {\n","    'regressor__max_depth': [3, 5, 10, 20, 30],\n","    'regressor__min_samples_split': [2, 4, 6]\n","}\n","\n","# Set up the grid search with cross-validation\n","grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n","\n","X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n","# Fit the grid search to the data\n","grid_search.fit(X_train, y_train)\n","\n","# Get the best estimator\n","best_model = grid_search.best_estimator_\n","\n","# Predict and evaluate\n","y_pred_valid = best_model.predict(X_valid)\n","mse = mean_squared_error(y_valid, y_pred_valid)\n","r2 = r2_score(y_valid, y_pred_valid)\n","\n","print(f\"Best model - MSE: {mse:.2f}, R^2: {r2:.2f}\")\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["{'regressor__max_depth': 30, 'regressor__min_samples_split': 6}"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["grid_search.best_params_"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Mean Price for Surge = 1:\n","        source        destination                car_type      price\n","0    Back Bay  Boston University                    Base   8.002237\n","1    Back Bay  Boston University                 Base XL  13.023863\n","2    Back Bay  Boston University                  Luxury  16.054951\n","3    Back Bay  Boston University              Luxury SUV  25.960104\n","4    Back Bay  Boston University                  Shared   6.374568\n","..        ...                ...                     ...        ...\n","427  West End      South Station                 Base XL  14.167363\n","428  West End      South Station                  Luxury  18.524408\n","429  West End      South Station              Luxury SUV  28.076548\n","430  West End      South Station                  Shared   7.013661\n","431  West End      South Station  Wheel Chair Accessible   8.378272\n","\n","[432 rows x 4 columns]\n","\n","Mean Price for Surge > 1:\n","        source              destination    car_type      price\n","0    Back Bay        Boston University        Base  11.160377\n","1    Back Bay        Boston University     Base XL  17.674528\n","2    Back Bay        Boston University      Luxury  23.599057\n","3    Back Bay        Boston University  Luxury SUV  40.344340\n","4    Back Bay                   Fenway        Base  10.849057\n","..        ...                      ...         ...        ...\n","283  West End  Northeastern University  Luxury SUV  46.771429\n","284  West End            South Station        Base  10.592593\n","285  West End            South Station     Base XL  17.944444\n","286  West End            South Station      Luxury  23.444444\n","287  West End            South Station  Luxury SUV  36.685185\n","\n","[288 rows x 4 columns]\n"]}],"source":["import pandas as pd\n","\n","# Assuming df is your DataFrame\n","df = get_cleaned_data()\n","# Filter for surge = 1 and calculate mean price\n","df_surge_1 = df[df['surge_multiplier'] == 1]\n","mean_price_surge_1 = df_surge_1.groupby(['source', 'destination', 'car_type'])['price'].mean()\n","\n","# Filter for surge > 1 and calculate mean price\n","df_surge_greater_1 = df[df['surge_multiplier']  > 1]\n","mean_price_surge_greater_1 = df_surge_greater_1.groupby(['source', 'destination', 'car_type'])['price'].mean()\n","\n","\n","mean_price_surge_1 = mean_price_surge_1.reset_index()\n","mean_price_surge_greater_1 = mean_price_surge_greater_1.reset_index()\n","\n","# Output the results\n","print(\"Mean Price for Surge = 1:\\n\", mean_price_surge_1)\n","print(\"\\nMean Price for Surge > 1:\\n\", mean_price_surge_greater_1)\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source</th>\n","      <th>destination</th>\n","      <th>car_type</th>\n","      <th>price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Back Bay</td>\n","      <td>Boston University</td>\n","      <td>Base</td>\n","      <td>8.002237</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Back Bay</td>\n","      <td>Boston University</td>\n","      <td>Base XL</td>\n","      <td>13.023863</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Back Bay</td>\n","      <td>Boston University</td>\n","      <td>Luxury</td>\n","      <td>16.054951</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Back Bay</td>\n","      <td>Boston University</td>\n","      <td>Luxury SUV</td>\n","      <td>25.960104</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Back Bay</td>\n","      <td>Boston University</td>\n","      <td>Shared</td>\n","      <td>6.374568</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>427</th>\n","      <td>West End</td>\n","      <td>South Station</td>\n","      <td>Base XL</td>\n","      <td>14.167363</td>\n","    </tr>\n","    <tr>\n","      <th>428</th>\n","      <td>West End</td>\n","      <td>South Station</td>\n","      <td>Luxury</td>\n","      <td>18.524408</td>\n","    </tr>\n","    <tr>\n","      <th>429</th>\n","      <td>West End</td>\n","      <td>South Station</td>\n","      <td>Luxury SUV</td>\n","      <td>28.076548</td>\n","    </tr>\n","    <tr>\n","      <th>430</th>\n","      <td>West End</td>\n","      <td>South Station</td>\n","      <td>Shared</td>\n","      <td>7.013661</td>\n","    </tr>\n","    <tr>\n","      <th>431</th>\n","      <td>West End</td>\n","      <td>South Station</td>\n","      <td>Wheel Chair Accessible</td>\n","      <td>8.378272</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>432 rows × 4 columns</p>\n","</div>"],"text/plain":["       source        destination                car_type      price\n","0    Back Bay  Boston University                    Base   8.002237\n","1    Back Bay  Boston University                 Base XL  13.023863\n","2    Back Bay  Boston University                  Luxury  16.054951\n","3    Back Bay  Boston University              Luxury SUV  25.960104\n","4    Back Bay  Boston University                  Shared   6.374568\n","..        ...                ...                     ...        ...\n","427  West End      South Station                 Base XL  14.167363\n","428  West End      South Station                  Luxury  18.524408\n","429  West End      South Station              Luxury SUV  28.076548\n","430  West End      South Station                  Shared   7.013661\n","431  West End      South Station  Wheel Chair Accessible   8.378272\n","\n","[432 rows x 4 columns]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["mean_price_surge_1"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source</th>\n","      <th>destination</th>\n","      <th>car_type</th>\n","      <th>price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Back Bay</td>\n","      <td>Boston University</td>\n","      <td>Base</td>\n","      <td>11.160377</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Back Bay</td>\n","      <td>Boston University</td>\n","      <td>Base XL</td>\n","      <td>17.674528</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Back Bay</td>\n","      <td>Boston University</td>\n","      <td>Luxury</td>\n","      <td>23.599057</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Back Bay</td>\n","      <td>Boston University</td>\n","      <td>Luxury SUV</td>\n","      <td>40.344340</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Back Bay</td>\n","      <td>Fenway</td>\n","      <td>Base</td>\n","      <td>10.849057</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>283</th>\n","      <td>West End</td>\n","      <td>Northeastern University</td>\n","      <td>Luxury SUV</td>\n","      <td>46.771429</td>\n","    </tr>\n","    <tr>\n","      <th>284</th>\n","      <td>West End</td>\n","      <td>South Station</td>\n","      <td>Base</td>\n","      <td>10.592593</td>\n","    </tr>\n","    <tr>\n","      <th>285</th>\n","      <td>West End</td>\n","      <td>South Station</td>\n","      <td>Base XL</td>\n","      <td>17.944444</td>\n","    </tr>\n","    <tr>\n","      <th>286</th>\n","      <td>West End</td>\n","      <td>South Station</td>\n","      <td>Luxury</td>\n","      <td>23.444444</td>\n","    </tr>\n","    <tr>\n","      <th>287</th>\n","      <td>West End</td>\n","      <td>South Station</td>\n","      <td>Luxury SUV</td>\n","      <td>36.685185</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>288 rows × 4 columns</p>\n","</div>"],"text/plain":["       source              destination    car_type      price\n","0    Back Bay        Boston University        Base  11.160377\n","1    Back Bay        Boston University     Base XL  17.674528\n","2    Back Bay        Boston University      Luxury  23.599057\n","3    Back Bay        Boston University  Luxury SUV  40.344340\n","4    Back Bay                   Fenway        Base  10.849057\n","..        ...                      ...         ...        ...\n","283  West End  Northeastern University  Luxury SUV  46.771429\n","284  West End            South Station        Base  10.592593\n","285  West End            South Station     Base XL  17.944444\n","286  West End            South Station      Luxury  23.444444\n","287  West End            South Station  Luxury SUV  36.685185\n","\n","[288 rows x 4 columns]"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["mean_price_surge_greater_1\n"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["merged_surge_info = mean_price_surge_1.merge(mean_price_surge_greater_1, on = ['source', 'destination', 'car_type'] )"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["merged_surge_info['mean_diff']= merged_surge_info['price_x'] - merged_surge_info['price_y']"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"data":{"text/plain":["-7.35146569832585"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["merged_surge_info['mean_diff'].mean()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"c12a693207de4a0d92eabf24fb01f952","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}
